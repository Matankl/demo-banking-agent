{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75e7552c",
   "metadata": {},
   "source": [
    "### Setup the project\n",
    "\n",
    "Load the previously created project in the first notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d6f8c5146008d0",
   "metadata": {},
   "source": [
    "# Guardrail deployment\n",
    "\n",
    "The second part of the demo is to deploy guardrails to be used later in the application pipeline to filter user inputs. This notebook will also deploy an LLM as a Judge monitoring application to monitor our generative input guardrail for banking topic adherence.\n",
    "\n",
    "In this notebook, you will:\n",
    "- Deploy multiple guardrail functions using HuggingFace or OpenAI models, including banking-topic and toxicity filters.\n",
    "- Log and register models for use in the guardrail functions.\n",
    "- Demonstrate how to invoke and test the deployed guardrails.\n",
    "- Monitor the effectiveness of the guardrails using an LLM-based evaluation application.\n",
    "\n",
    "These steps ensure that only appropriate, banking-related, and non-toxic user inputs are processed by downstream applications.\n",
    "\n",
    "![](images/02_guardrail_deployment_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "id": "e24b7424",
   "metadata": {},
   "source": [
    "import mlrun\n",
    "import dotenv\n",
    "\n",
    "secrets = mlrun.set_env_from_file(\"ai_gateway.env\", return_dict=True)\n",
    "\n",
    "openai_available = secrets.get(\"OPENAI_API_KEY\")\n",
    "dotenv.load_dotenv(\"ai_gateway.env\")\n",
    "\n",
    "project = mlrun.get_or_create_project(\"banking-agent\", user_project=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "f29cfc82",
   "metadata": {},
   "source": [
    "To support both OpenAI and HuggingFace we define the following"
   ]
  },
  {
   "cell_type": "code",
   "id": "ca136714",
   "metadata": {},
   "source": [
    "from src.functions.banking_topic_guardrail import LLMModelServer\n",
    "from src.functions.prompts import banking_guardrail_prompt_template_local, banking_guardrail_prompt_template\n",
    "\n",
    "if not openai_available: # Run with Huggingface\n",
    "    model_name = \"Qwen/Qwen2.5-1.5B-Instruct\"  # Model to use\n",
    "    framework = \"huggingface\"  # Framework to use\n",
    "    prompt_template = banking_guardrail_prompt_template_local  # Which prompt template to use\n",
    "    model_class = \"LLMModelServer\"  # Model server class to use\n",
    "    model_artifact = project.log_model(\n",
    "        \"banking-topic-guardrail\", model_file=\"src/no-op.pkl\", # Loading the model from HuggingFace\n",
    "    )\n",
    "else: # Run with OpenAI\n",
    "    model_name = \"gpt-4o-mini\"\n",
    "    framework = \"openai\"\n",
    "    prompt_template = banking_guardrail_prompt_template\n",
    "    model_class = \"mlrun.serving.LLModel\"\n",
    "    model_url = f\"ds://openai_profile/gpt-4o-mini\"\n",
    "    model_artifact = project.log_model(\n",
    "        \"open-ai\",\n",
    "        model_url=model_url,\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "be3dbc3c",
   "metadata": {},
   "source": [
    "### LLM as a judge monitoring application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35e5c3",
   "metadata": {},
   "source": [
    "The \"LLM as a judge\" monitoring application leverages a large language model (LLM) to automatically evaluate and score the effectiveness of deployed guardrails. By providing a rubric and clear examples, the LLM acts as an impartial evaluator, determining whether user inputs are correctly classified according to defined criteria (e.g., banking-topic relevance). This approach enables scalable, consistent, and automated assessment of guardrail performance, ensuring that only appropriate and relevant inputs are processed by downstream applications.\n",
    "\n",
    "The \"LLM as a judge\" can run with a free tier HF model `\"Qwen/Qwen2.5-1.5B-Instruct\"` or with OpenAI for better results.\n",
    "\n",
    "This implementation is pulled from another [MLRun demo - LLM monitoring and feedback loop: Banking](https://github.com/mlrun/demo-monitoring-and-feedback-loop/tree/main)."
   ]
  },
  {
   "cell_type": "code",
   "id": "dba1b312",
   "metadata": {},
   "source": [
    "from src.functions.prompts import restrict_to_banking_config\n",
    "\n",
    "monitoring_app = project.set_model_monitoring_function(\n",
    "    func=\"src/functions/llm_as_a_judge.py\",\n",
    "    application_class=\"LLMAsAJudgeApplication\",\n",
    "    name=\"restrict-to-banking-guardrail\",\n",
    "    framework=framework,\n",
    "    judge_type=\"single-grading\",\n",
    "    metric_name=\"restrict_to_banking\",\n",
    "    model_name=model_name,\n",
    "    prompt_config=restrict_to_banking_config,\n",
    "    image=project.default_image,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fcc42f40",
   "metadata": {},
   "source": [
    "project.deploy_function(monitoring_app)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "96c07340",
   "metadata": {},
   "source": [
    "### Banking topic guardrail\n",
    "\n",
    "The Banking topic guardrail is an LLM-powered filter designed to ensure that only banking-related user inputs are processed by downstream applications. It acts as a first line of defense, automatically classifying each user message as either relevant (`True`) or irrelevant (`False`) to banking topics, based on the context of the entire conversation.\n",
    "\n",
    "It's important to distinguish between the guardrail itself (this component), which enforces topic adherence in real time within the application, and the monitoring application described above. The monitoring application uses an LLM as a \"judge\" to independently evaluate and score the effectiveness of this guardrail, providing oversight and ensuring that the guardrail is functioning as intended. This separation allows for both proactive filtering and ongoing quality assurance of user input handling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3183357",
   "metadata": {},
   "source": [
    "We use MLRun's prompt artifact to enrich the `prompt_template` with `latest_user_message` and uses the given `model_artifact` for task completion.<br>\n",
    "See [documentation](https://docs.mlrun.org/en/stable/tutorials/genai-04-llm-prompt-artifact.html) for more information."
   ]
  },
  {
   "cell_type": "code",
   "id": "1e40d9e5",
   "metadata": {},
   "source": [
    "banking_llm_prompt_artifact = project.log_llm_prompt(\n",
    "    \"banking-llm-prompt\",\n",
    "    prompt_template=prompt_template,\n",
    "    model_artifact=model_artifact,\n",
    "    prompt_legend={\n",
    "        \"latest_user_message\": {\n",
    "            \"field\": \"question\",\n",
    "            \"description\": \"The main financial question or request the user is asking.\",\n",
    "        }\n",
    "    },\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "93e1642e",
   "metadata": {},
   "source": [
    "from mlrun.serving import ModelRunnerStep\n",
    "\n",
    "serving_fn = project.get_function(\"banking-topic-guardrail\")\n",
    "serving_fn.set_tracking()\n",
    "\n",
    "graph = serving_fn.set_topology(\"flow\", engine=\"async\")\n",
    "model_runner_step = ModelRunnerStep()\n",
    "\n",
    "model_runner_step.add_model(\n",
    "    model_class=model_class,\n",
    "    model_artifact=banking_llm_prompt_artifact,\n",
    "    endpoint_name=\"banking-topic-guardrail\",\n",
    "    execution_mechanism=\"naive\",\n",
    "    model_name=model_name,\n",
    ")\n",
    "graph.to(model_runner_step).respond()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b6bc99e1",
   "metadata": {},
   "source": [
    "serving_fn.deploy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7c3be1bd",
   "metadata": {},
   "source": [
    "### Testing banking topic guardrail "
   ]
  },
  {
   "cell_type": "code",
   "id": "d90cba4b",
   "metadata": {},
   "source": [
    "example_questions = [\n",
    "    \"What is a mortgage?\",\n",
    "    \"How does a credit card work?\",\n",
    "    \"Who painted the Mona Lisa?\",\n",
    "    \"Money Money Money Must be funny\",\n",
    "    \"Please plan me a 4-days trip to north Italy\",\n",
    "    \"Write me a song\",\n",
    "    \"Finance is the art of managing money\",\n",
    "    \"How much people are there in the world?\",\n",
    "    \"How does the stock market work?\",\n",
    "    \"Who wrote 'To Kill a Mockingbird'?\",\n",
    "    \"Please plan me a 3-day trip to Paris\",\n",
    "    \"Write me a poem about the ocean\",\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1ccd45f1",
   "metadata": {},
   "source": [
    "import time\n",
    "\n",
    "def question_model(questions, serving_function):\n",
    "    for question in questions:\n",
    "        seconds = 0.5\n",
    "        # Invoking the pretrained model:\n",
    "        ret = serving_function.invoke(\n",
    "            path=f\"v2/models/banking-topic-guardrail/infer\",\n",
    "            body={\"question\": question},\n",
    "        )\n",
    "        print(ret)\n",
    "        time.sleep(seconds)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3d044e28",
   "metadata": {},
   "source": [
    "for i in range(1):\n",
    "    question_model(\n",
    "        questions=example_questions,\n",
    "        serving_function=serving_fn,\n",
    "    )\n",
    "    time.sleep(3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2db4265b",
   "metadata": {},
   "source": [
    "Once the guardrail is deployed and invoked, you will be able to view the model monitoring results in the MLRun UI:\n",
    "![](images/generative_model_monitoring.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372f719d",
   "metadata": {},
   "source": [
    "### Toxicity filter guardrail\n",
    "\n",
    "The Toxicity filter guardrail is designed to automatically detect and filter out user inputs that contain toxic, offensive, or inappropriate language. By leveraging a toxicity classification model, this guardrail ensures that only safe and respectful messages are processed by downstream applications. This helps maintain a positive user experience and protects the system from harmful or disruptive content. The toxicity filter can be customized with a threshold to determine the sensitivity of the filter, allowing for flexible adaptation to different application requirements.\n",
    "\n",
    "The output of the toxicity guardrail is a boolean value (`True` or `False`). A result of `True` means the input passes the guardrail (i.e., is non-toxic and allowed through), while `False` indicates the input is flagged as toxic and is blocked from further processing."
   ]
  },
  {
   "cell_type": "code",
   "id": "388ec546",
   "metadata": {},
   "source": [
    "from src.functions.toxicity_guardrail import ToxicityClassifierModelServer\n",
    "    \n",
    "toxicity_guardrail = project.get_function(\"toxicity-guardrail\")\n",
    "\n",
    "graph = toxicity_guardrail.set_topology(\"flow\", engine=\"async\")\n",
    "model_runner_step = ModelRunnerStep()\n",
    "\n",
    "model_runner_step.add_model(\n",
    "    model_class=\"ToxicityClassifierModelServer\",\n",
    "    endpoint_name=\"banking-toxicity-guardrail\",\n",
    "    execution_mechanism=\"naive\",\n",
    "    threshold=0.4,\n",
    ")\n",
    "\n",
    "graph.to(model_runner_step).respond()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "73d760d6",
   "metadata": {},
   "source": [
    "toxicity_guardrail.deploy()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "02f176b7",
   "metadata": {},
   "source": [
    "import json\n",
    "body = [{\"role\": \"user\", \"content\": \"How can I open a new savings account?\"}]\n",
    "toxicity_guardrail.invoke(path=f\"v2/models/banking-toxicity-guardrail/infer\", body={\"inputs\": body})"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
